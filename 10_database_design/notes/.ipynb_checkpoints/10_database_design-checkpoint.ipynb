{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing, Storing, and Organizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main question is this course is: *how shall we organize and manage data?*\n",
    "\n",
    "We need to consider:\n",
    "- **Schemas**:\n",
    "    - How should the data bee logically stored?\n",
    "- **Normalization**:\n",
    "    - Should data have minimal transparency and redundancy?\n",
    "- **Views**:\n",
    "    - What joins will be done most often?\n",
    "- **Access control**:\n",
    "    - Should all users of the data have the same level of access?\n",
    "- **DBMS**:\n",
    "    - How to pick between SQL and NoSQL options?\n",
    "    \n",
    "It depends on the intended use of the data: there are trade-offs of speed, memory and cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLTP and OLAP\n",
    "\n",
    "These are approaches to processing data. \n",
    "\n",
    "OLTP:\n",
    "- Online Transaction Processing\n",
    "- Support daily transactions\n",
    "- Application-oriented\n",
    "- Up-to-date, operational\n",
    "- Snapshot, gigabytes\n",
    "- Simple transactions and frequent updates\n",
    "- Thousands of users\n",
    "\n",
    "OLAP\n",
    "- Online Analytical Processing\n",
    "- Report and analyze data\n",
    "- Subject-oriented\n",
    "- Consolidated, historical data\n",
    "- Archive data so usually terabytes\n",
    "- Complex, aggregate queries & limited updates\n",
    "- Hundreds of users (analysts and data scientists)\n",
    "\n",
    "OLAP and OLTP systems *need* each other. OLTP is usually stored in an operational database which is pulled and cleaned to create an OLAP data warehouse.\n",
    "\n",
    "## Pre-implementation\n",
    "\n",
    "- Step back and figure out business requirements\n",
    "- Difference between OLAP and OLTP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing data\n",
    "\n",
    "Three main ways in which to store data:\n",
    "\n",
    "1. Structured Data\n",
    "    - Follows a schema\n",
    "    - Defined data types and relationships\n",
    "2. Unstructured data\n",
    "    - Schemaless\n",
    "    - Most data in the world\n",
    "3. Semi-structured\n",
    "    - Does not follow a larger schema\n",
    "    - Self-describing structure\n",
    "    \n",
    "## Storing data beyond traditional databases\n",
    "\n",
    "Decades ago, traditional databases were enough but increasing requirements created new options.\n",
    "\n",
    "- Traditional databases\n",
    "    - For storing real-time relational structured data (OLTP)\n",
    "- Data warehouses\n",
    "    - For analyzing archived structured data (OLAP)\n",
    "- Data lakes\n",
    "    - For storing data of all structures (flexibility and scalability)\n",
    "    - For analyzing big data\n",
    "    \n",
    "### Data Warehouses\n",
    "\n",
    "- Optimised for analytics\n",
    "    - Organised for reading and aggregating data\n",
    "    - Usually read-only\n",
    "- Contains data from multiple sources\n",
    "- Massively Parallel Processing\n",
    "- Typically uses a denormalized schema and dimensional modeling\n",
    "- Examples: Amazon Redshift, Azure SQL Data Warehouse, Google Big Query\n",
    "\n",
    "#### Data mart\n",
    "\n",
    "- Subset of data warehouses\n",
    "- Dedicated to a specific topic (HR, supply chain, marketing, sales, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Lakes\n",
    "\n",
    "Data lakes store unstructured data in a cost-effective way.\n",
    "\n",
    "- Store all types of data at a lower cost\n",
    "    - e.g. raw, operational databases, IoT device logs, real-time, relational and non-relational\n",
    "- Retains all data and can take petabytes\n",
    "- Schema-or-read as opposed to schema-on-write\n",
    "- Need to catalog data otherwise becomes a data swap\n",
    "- Run big data analytics using services like Apache Spark and Hadoop\n",
    "    - Useful for deep learning and data discovery because activities require so much data\n",
    "- Examples: Google Cloud Storrage, Amazon S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to store data\n",
    "\n",
    "When we think of *where* to store data, we need to consider *how* data gets there and in what form. There are two main options:\n",
    "- ETL\n",
    "    - Extract Transform Load\n",
    "    - More traditional approach for warehousing and small scale analytics\n",
    "    - Data is transformed before being loaded into storage, usually to follow the warehouse's schema\n",
    "- ELT\n",
    "    - Big Data projects\n",
    "    - Data is stored in its native form in a data lake\n",
    "    - The portions of data are transformed for different purposes, from building a data warehouse to doing deep learning\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Design\n",
    "\n",
    "Database design determines how data is logically stored\n",
    "    - How is data going to be updated and read?\n",
    "\n",
    "There are two main concepts to understand when it comes to database design: database modeling and database schemas\n",
    "\n",
    "### Database Models\n",
    "\n",
    "These are the high-level specifications for the database structure.\n",
    "\n",
    "- Most popular is the relational model\n",
    "    - Alternatives are NoSQL models, objecet-oriented, network\n",
    "\n",
    "### Database schemas\n",
    "\n",
    "These are the blueprint of the database.\n",
    "\n",
    "- They are the implementation of the database model\n",
    "    - Defines tables, field, relationships, indexes, and views\n",
    "    - When inserting data in relational databases, schemas must be respected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modeling\n",
    "\n",
    "There are 3 levels to a data model:\n",
    "\n",
    "1. Conceptual data model\n",
    "    - Describes entities, relationships and attributes\n",
    "    - Tools: data structure diagrams, entity-relational diagrams and UML diagrams\n",
    "2. Logical data model\n",
    "    - Tools: database models and schemas, relational model and star schema\n",
    "3. Physical data model\n",
    "    - Tools: partitions, CPUs, indexes, backup systems and tablespaces\n",
    "    \n",
    "These ensure consistency and provide a plan for implementation and use.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensional Modeling\n",
    "\n",
    "Fact tables:\n",
    "- Decided by business use-case\n",
    "- Hold records of a metric\n",
    "- Changes regularly\n",
    "- Connects to dimensions via foreign keys\n",
    "\n",
    "Dimension tables\n",
    "- Holds descriptions of attributes\n",
    "- Does not change as often"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Schemas and Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The star schema is the simplest form of the dimensional model\n",
    "> Start schema is made up of two tables: fact and dimension tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall on star schema\n",
    "\n",
    "Fact tables:\n",
    "- Hold records of a metric\n",
    "- Change regularly\n",
    "- Connect to dimensions via foreign keys\n",
    "\n",
    "Dimension tables:\n",
    "- Hold description of values\n",
    "- Do not change as often"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snowflake schema\n",
    "\n",
    "Snowflake schema is an extension of the star schema: while the star schema extends one dimension, the snowflake schema extends more than one dimension. That's because the dimension tables are *normalized*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "Normalization is technique to divide tables into smaller tables and reduce redundancy and increase data integrity.\n",
    "\n",
    "The basic idea is to find repeating groups of data and create new tables for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foreign keys\n",
    "\n",
    "Foreign key references are essential to both the snowflake and star schema. When creating either of these schemas, correctly setting up the foreign keys is vital because they connect dimensions to the fact table. They also enforce a one-to-many relationship, because unless otherwise specified, a foreign key can appear more than once in a table and primary key can appear only once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized and denormalized datasets\n",
    "\n",
    "- Normalization saves space\n",
    "    - Even though there are more tables, there is less redundancy\n",
    "- Normalization ensure better data integrity\n",
    "    1. Enforces data consistency\n",
    "        - Must respect naming conventions because of referential integrity\n",
    "    2. Safer updating, removing and inserting\n",
    "        - Less data redundancy = less records to alter\n",
    "    3. Easier to redesign by extending\n",
    "        - Smaller tables are easier to extend than larger tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and cons of normalization\n",
    "\n",
    "Advantages:\n",
    "- Normalization eliminates data redundancy: save on storage\n",
    "- Better data integrity: accurate and consistent data\n",
    "\n",
    "Disadvantages:\n",
    "- Complex queries require more CPU\n",
    "\n",
    "Deciding on the normalization vs denormalization comes down to how intensive the reads/writes on the database are going to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLTP and OLAP\n",
    "\n",
    "OLTP is highly normalized:\n",
    "- Write intensive\n",
    "- Prioritize quicker and safer insertion of data\n",
    "\n",
    "OLAP:\n",
    "- Read intensive\n",
    "- Prioritize quicker queries for analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Forms\n",
    "\n",
    "The goals of normalization are to:\n",
    "- Be able to characterize the level of redundancy in a relational schema\n",
    "- Provide mechanisms for transforming schemas in order to remove redundancy\n",
    "\n",
    "There are different levels of normal forms:\n",
    "- First normal form (1NF)\n",
    "- Second normal form (2NF)\n",
    "- Third normal form (3NF)\n",
    "- Elementary key normal form (EKNF)\n",
    "- Boyce-Codd normal form (BCNF)\n",
    "- Fourth normal form (4NF)\n",
    "- Essential tuple normal form (ETNF)\n",
    "- Fifth normal form (5NF)\n",
    "- Domain-key normal form (DKNF)\n",
    "- Sixth normal form (6NF)\n",
    "\n",
    "### 1NF\n",
    "\n",
    "- Each record must be unique - no duplicate rows\n",
    "- Each cell must hold one values (no tuples, commas, etc)\n",
    "\n",
    "### 2NF\n",
    "\n",
    "- Must satisfy 1NF\n",
    "- If primary key is one column then it automatically satisfies 2NF\n",
    "- If there is a composite primary key then each non-key column must be dependent on all the keys\n",
    "\n",
    "### 3NF\n",
    "\n",
    "- Satisfies 2NF\n",
    "- No transitive dependencies: non-key columns can't depend on other non-key columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data anomalies\n",
    "\n",
    "There are 3 main errors which come from not normalizing enough:\n",
    "1. Update\n",
    "    - data inconsistency which can arise when updating a table with redundancy\n",
    "    - user updating needs to know about redundancy\n",
    "2. Insertion\n",
    "    - unable to add a record due to missing attributes\n",
    "3. Deletion\n",
    "    - when we delete a record and unintentionally delete other data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Views\n",
    "\n",
    "A view is a result set of a stored query on the data, which the database users can query just as they would in a persistent database collection object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simpler terms, think of it as an Alfred snippet for a query. We can save a query as a view which has many advantages:\n",
    "- Simplifies the query a lot (for example by not having to type so many `JOIN`s)\n",
    "- Gives us finer control over who can access what in a database\n",
    "- Does not take up memory (only the space to store the query itself)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE VIEW scifi_books AS\n",
    "-- Annoying query we don't want to type all the time\n",
    "SELECT title, author, genre\n",
    "FROM dim_book_sf\n",
    "JOIN dim_genre_df ON dim_genre_sf.genre_id = dim_book_sf.genre_id\n",
    "JOIN dim_author_sf ON dim_author_sf.author_id = dim_book_sf.author_id\n",
    "WHERE dim_genre_sf.genr = \"science fiction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query a view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT * FROM scifi_books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behind the scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT * FROM\n",
    "(SELECT title, author, genre\n",
    "FROM dim_book_sf\n",
    "JOIN dim_genre_df ON dim_genre_sf.genre_id = dim_book_sf.genre_id\n",
    "JOIN dim_author_sf ON dim_author_sf.author_id = dim_book_sf.author_id\n",
    "WHERE dim_genre_sf.genr = \"science fiction\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing views in PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- See all the views we have\n",
    "SELECT * FROM INFORMATION_SCHEMA.views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- See all the views we have except system views\n",
    "SELECT * FROM INFORMATION_SCHEMA.views\n",
    "WHERE table_schema NOT IN ('pg_catalog', 'information_schema');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grant and revoke access to a view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRANT priviledge(s) or REVOKE priviledge(s)\n",
    "ON object\n",
    "TO role or FROM role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Priviledges: `SELECT`, `INSERT`, `UPDATE`, `DELETE`, etc\n",
    "- Objects: table, view, schema, etc\n",
    "- Roles: a database user or a group of database users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- notice that we \"grant to\" and \"revoke from\"\n",
    "GRANT UPDATE ON ratings TO PUBLIC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVOKE INSERT ON films FROM db_user;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating a view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPDATE films SET kind = \"Dramatic\" WHERE kind = \"Drama\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating views is a bad idea because what is updated is the underlying table, not the view (naturally, since the view does not exist in memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not all views are updatable**:\n",
    "- Views must be made up of one table;\n",
    "- Must not use window or aggregate functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same applies for `INSERT`in into views\n",
    "\n",
    "> Do not modify data through views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping a view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP VIEW view_name [CASCADE | RESTRICT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `CASCADE`:\n",
    "    - drops view and any objects that depend on the view\n",
    "- `RESTRICT` (default):\n",
    "    - returns an error if there are objects that depend on the view\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redefining a view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE OR REPLACE VIEW view_name AS new_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If a view with `view_name` already exists, it is replaced\n",
    "- `new_query` must generate the same column names, order, and data types as the old query\n",
    "- The column output may be different\n",
    "- New columns may be added at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materialised Views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of views:\n",
    "1. Views\n",
    "    - aka non-materialised views\n",
    "    - how we've defined views so far\n",
    "2. Materialised views\n",
    "    - physically materialised\n",
    "    - stores the *query results* not the the query\n",
    "        - queries just access the stored query results\n",
    "    - refreshed or rematerialised when prompted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to use materialised views?\n",
    "\n",
    "- Long running queries\n",
    "- Underlying query results don't change often\n",
    "- Data warehouses because OLAP is not write-intensive\n",
    "    - Save on computational cost of frequent queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Materialised Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE MATERIALIZED VIEW my_view AS SELECT * FROM existing_table;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFRESH MATERIALIZED VIEW my_view;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing dependencies\n",
    "\n",
    "- Materialised views often depend on other materialised views\n",
    "- Creates a dependency chain when refreshing views\n",
    "- Not the most efficient to refresh all views at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Roles\n",
    "\n",
    "- Manage database access permissions\n",
    "- A database role is an entity that contains information that:\n",
    "    - Defines the role's priviledges\n",
    "        - Can you login?\n",
    "        - Can you create databases?\n",
    "        - Can you write to tables?\n",
    "    Interact with the client authentication system\n",
    "        - Password\n",
    "- Roles can be assigned to one or more users\n",
    "- Roles are global across a database cluster installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- empty role\n",
    "CREATE ROLE data_analyst;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: creating a role for an intern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE ROLE intern WITH PASSWORD 'PasswordForIntern' VALID UNTIL '2020-01-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: creating admin role with the ability to create databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE ROLE admin CREATEDB;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- granting right to admin to create new roles\n",
    "ALTER ROLE admin CREATEROLE;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `GRANT` and `REVOKE` priviledges from roles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRANT UPDATE ON ratings TO data_analyst;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVOKE UPDATE ON ratings FROM data_analyst;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of priviledges:\n",
    "- `SELECT`\n",
    "- `INSERT`\n",
    "- `UPDATE`\n",
    "- `DELETE`\n",
    "- `TRUNCATE`\n",
    "- `REFERENCES`\n",
    "- `TRIGGER`\n",
    "- `CREATE`\n",
    "- `CONNECT`\n",
    "- `TEMPORARY`\n",
    "- `EXECUTE`\n",
    "- `USAGE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users and groups are *both* roles\n",
    "\n",
    "A role is an entity that can function as a user and/or a group:\n",
    "- User roles\n",
    "- Group roles\n",
    "\n",
    "Note:\n",
    "\n",
    "- A role can be a user role or a group role\n",
    "- A role may be a member of other roles\n",
    "    - We can the larger role a *group*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE ROLE data_analyst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- alex joins the company\n",
    "CREATE ROLE alex WITH PASSWORD 'PasswordForIntern' VALID UNTIL '2020-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- he can now do data analyst work\n",
    "GRANT data_analyst TO alex;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- now he cant anymore\n",
    "REVOKE data_analyst FROM alex;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Create an admin role\n",
    "CREATE ROLE admin WITH CREATEDB CREATEROLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Grant data_scientist update and insert privileges\n",
    "GRANT UPDATE, INSERT ON long_reviews TO data_scientist;\n",
    "\n",
    "-- Give Marta's role a password\n",
    "ALTER ROLE marta WITH PASSWORD 's3cur3p@ssw0rd';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Add Marta to the data scientist group\n",
    "GRANT data_scientist TO marta;\n",
    "\n",
    "-- Celebrate! You hired data scientists.\n",
    "\n",
    "-- Remove Marta from the data scientist group\n",
    "REVOKE data_scientist FROM marta;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table partitioning\n",
    "\n",
    "### Why partition data?\n",
    "\n",
    "When tables grow, tables tend to become very slow. As a certain point, it can make sense to split data into smaller parts.\n",
    "\n",
    "> Partitioning fits into the *physical data model*\n",
    "\n",
    "###  Types of partitioning\n",
    "\n",
    "There are 2 types of partioning\n",
    "1. Vertical\n",
    "    - Split the table vertically through columns (even when it's fully normalized!)\n",
    "    - Example: breaking the `long_description` of the Pitchfork reviews into a separate column (it eats of CPU time and isn't retrieved very often)\n",
    "2. Horizontal\n",
    "    - Splitting tables up over their rows\n",
    "    - Example: separating 2019 and 2018; partitioning by quarter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TABLE sales (\n",
    "    -- creating a bunch of columns\n",
    "    timestamp DATE NOT NULL\n",
    ")\n",
    "PARTITION BY RANGE (timestamp)\n",
    "\n",
    "CREATE TABLE sales_2019_q1 PARTITION OF sales\n",
    "    FOR VALUES FROM ('2019-01-01') TO ('2019-03-31');\n",
    "    \n",
    "CREATE TABLE sales_2019_q4 PARTITION OF sales\n",
    "    FOR VALUES FROM ('2019-09-01') TO ('2019-12-31');    \n",
    "CREATE INDEX ON sales ('timestamp');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and cons of horizontal partitioning\n",
    "\n",
    "Pros:\n",
    "- Indices of heavily-used partitions fit in memory\n",
    "- Move to specific medium: slower vs. faster\n",
    "- Used for both OLAP and OLTP\n",
    "\n",
    "Cons:\n",
    "- Partitioning existing table can be a hassle\n",
    "    - Create a new table, copy over the data\n",
    "- Some constraints cannot be set\n",
    "    - We cannot set a PRIMARY KEY constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharding\n",
    "\n",
    "We can take partioning one step further and split the partition over several machines: this is called *sharding* (this is used in MPPs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For vertical partitioning, there is no specific syntax in PostgreSQL. You have to create a new table with particular columns and copy the data there. Afterward, you can drop the columns you want in the separate partition. If you need to access the full table, you can do so by using a JOIN clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Create a new table called film_descriptions\n",
    "CREATE TABLE film_descriptions (\n",
    "    film_id INT,\n",
    "    long_description TEXT\n",
    ");\n",
    "\n",
    "-- Copy the descriptions from the film table\n",
    "INSERT INTO film_descriptions\n",
    "SELECT film_id, long_description FROM film;\n",
    "    \n",
    "-- Drop the descriptions from the original table\n",
    "ALTER TABLE film DROP long_description;\n",
    "\n",
    "-- Join to view the original table\n",
    "SELECT * FROM film\n",
    "JOIN film_descriptions ON film.film_id = film_descriptions.film_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Create a new table called film_partitioned\n",
    "CREATE TABLE film_partitioned (\n",
    "  film_id INT,\n",
    "  title TEXT NOT NULL,\n",
    "  release_year TEXT\n",
    ")\n",
    "PARTITION BY LIST (release_year);\n",
    "\n",
    "-- Create the partitions for 2019, 2018, and 2017\n",
    "CREATE TABLE film_2019\n",
    "\tPARTITION OF film_partitioned FOR VALUES IN ('2019');\n",
    "    \n",
    "CREATE TABLE film_2018\n",
    "\tPARTITION OF film_partitioned FOR VALUES IN ('2018');\n",
    "    \n",
    "CREATE TABLE film_2017\n",
    "\tPARTITION OF film_partitioned FOR VALUES IN ('2017');\n",
    "    \n",
    "-- Insert the data into film_partitioned\n",
    "INSERT INTO film_partitioned\n",
    "SELECT film_id, title, release_year FROM film;\n",
    "\n",
    "-- View film_partitioned\n",
    "SELECT * FROM film_partitioned;    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Integration deals with the problem of combining data from several different sources and formats.\n",
    "\n",
    "Typical use cases are:\n",
    "- 360-degree customer view\n",
    "- Acquisitions (merging datasets from different companies)\n",
    "- Legacy systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "\n",
    "Transformations allow us to move data from different stores into something which can be fed into the unified data model. They are scheduled using an ETL tool (like Airflow), and should be tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking a DBMS\n",
    "\n",
    "A DBMS is a Database Management System\n",
    "\n",
    "It creates and maintains databases and manages 3 important aspects:\n",
    "- Data\n",
    "- Database schema\n",
    "- Database engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of DBMS\n",
    "\n",
    "There are two types of DBMS:\n",
    "1. SQL DBMS\n",
    "    - Relational Database Management System\n",
    "    - Based on relational model of data\n",
    "    - Query language: SQL\n",
    "    - **Best option when**:\n",
    "        - Data is structured and unchanging\n",
    "        - Data must be consistent\n",
    "    - Examples: SQL Server, PostgreSQL, Oracle\n",
    "2. NoSQL DBMS\n",
    "    - Less structured\n",
    "    - Document-centered rarther than table-centered\n",
    "    - Data doesn't have to fit into well-defined rows and columns\n",
    "    - **Best option when**:\n",
    "        - Rapid growth\n",
    "        - No clear schema definitions\n",
    "        - Large quantities of data\n",
    "    - Types: key-value store, document store, columnar database, graph database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoSQL DBMS\n",
    "\n",
    "There are 4 main types:\n",
    "\n",
    "1. Key-value store\n",
    "    - Combinations of keys and values\n",
    "        - Key is the unique identified\n",
    "        - Value can be anything\n",
    "    - Use case: shopping cart from an online buyer\n",
    "    - Example: Redis\n",
    "2. Document store\n",
    "    - Similar to key-value\n",
    "    - Values (i.e. documents) are structured\n",
    "    - Use case: content management\n",
    "    - Example: MongoDB\n",
    "3. Columnar database\n",
    "    - Stored data in columns\n",
    "    - Scalable\n",
    "    - Use case: big data analytics where speed is important\n",
    "    - Example: Apache Cassandra\n",
    "4. Graph database\n",
    "    - Data is interconnected and best represented as a graph\n",
    "    - Use case: social media data, recommendations\n",
    "    - Example: neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
